2022-04-17
- just wrote the single layer MetaLayer
- need to convert coo_matrxi to a subscriptable object
- think more deeply about how to handle the edge matrix, currently not embedding edge attributes 
- read through GNS paper to see that the relative (as compared to absolute) implementation yielded better performance because spatially invariant
- finish implementing model and try to get the point where I can train on something...

2022-04-18
- fixed the data types and got single MetaLayer running
- read through the MetaLayer docs and understand how it works (especially batch size?)
- tweak the shapes of the node model to maintain n_latent = 128
- wrap the MetaLayer into a class that has K MetaLayers stacked together
- then implement the Decoder

2022-04-19
- read MetaLayer docs
- tweaked shape to output n_latent = 128
- tomorrow: review my work so far and finish last 2 items from above

2022-04-20
- finished writing all the forward pass stuff 
- implement the fix so that the graph is built from the first entry in the trajectory file, not the configuration file
- wrap up the model so that it can train end-to-end
- try running a training loop

2022-04-21
- there is a discrepancy between the number of time steps I commanded to run the sim and how many I have? 
- commanded 1e5 but got 5e4? or maybe I changed it? 
- I also got printouts every 1e2 not every 1e3...may also have changed that...
- thinking about training loop  
    - can i train over graphs of different sizes? 
    - for each graph, do a gradient update after every time step, then repeat the whole process multiple times
    - what did the original authors do? -- not clear, need to dig through code I think
- things to build: 
    - rollout function - save the X for each time step in a .dat file so I can export directly to oxView
- todo list: 
    - review what I've built so far by updating the problem definition document
    - find things to improve on 
- wow the loss curve actually decreases...

2022-04-22
- TODO list:
    - add code to save checkpoints/the final model and reload and run a rollout 
    - update code to work with Eric's datasets
        -- pull ground truth torque and force
        -- rewrite loss function to use torque and force instead of accelerations --> or not? Just also record MAE wrt forces
    - implement mae function to compute - more robust to outliers 
        - maybe keep using mse for training tho? not sure...
        - average all atoms, over all time steps and over all timesteps
        - do MAE for force, MAE for torque report separately
    - write report
        - aim for 4 pages
    - randomly sample time frames from one trajectory -- want to maintain iid assumption
        -- do this rather than generate more data
        -- PAC theory: https://en.wikipedia.org/wiki/Probably_approximately_correct_learning

2022-04-23
- update rollout function to deal with different bounding boxes and energies

2022-04-25
- realized that I wasn't resetting X to the initial value for a new training epoch - it is fixed now
    -- investigating to see the effect that this fix has on my loss curves overall
- but I should also start the validation loop with the ground truth value of X, so I need to modify my function so that I can extract the X graph at an arbitrary time step
